!!python/object/apply:collections.OrderedDict
- - - batch_size
    - 512
  - - buffer_size
    - 100000
  - - callback
    - - envs.utils.callbacks.TrainingCallback
  - - ent_coef
    - auto
  - - env_wrapper
    - - utils.wrappers.HistoryWrapper:
          horizon: 10
  - - gamma
    - 0.99
  - - gradient_steps
    - -1
  - - learning_rate
    - 0.0003
  - - learning_starts
    - 10000
  - - n_timesteps
    - 1000000.0
  - - normalize
    - '{''norm_obs'': True, ''norm_reward'': False}'
  - - policy
    - MlpPolicy
  - - policy_kwargs
    - dict(net_arch=[400, 300])
  - - train_freq
    - - 1
      - episode
